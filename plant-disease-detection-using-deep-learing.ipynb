{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install Kaggle (if not present) and import libraries\n!pip install -q kaggle\n\n# Standard imports\nimport os, shutil, random\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models\n\nprint(\"TensorFlow version:\", tf.__version__)\n\nprint(\"GPU available:\", tf.test.is_gpu_available())\n","metadata":{"id":"1lG4Q-heq9MC","outputId":"be80403b-0818-4cf2-a466-03b9ae9dc7e4","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T14:46:40.830440Z","iopub.execute_input":"2025-09-17T14:46:40.830710Z","iopub.status.idle":"2025-09-17T14:47:04.058686Z","shell.execute_reply.started":"2025-09-17T14:46:40.830684Z","shell.execute_reply":"2025-09-17T14:47:04.057753Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T20:17:15.874008Z","iopub.execute_input":"2025-09-17T20:17:15.874704Z","iopub.status.idle":"2025-09-17T20:17:15.878533Z","shell.execute_reply.started":"2025-09-17T20:17:15.874678Z","shell.execute_reply":"2025-09-17T20:17:15.877779Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#for dataset download\n!kaggle datasets download -d emmarex/plantdisease\n\n# Unzip into folder 'plant_disease'\n!unzip -q plantdisease.zip -d plant_disease\n!ls -la plant_disease | sed -n '1,120p'","metadata":{"id":"7S4nZRulCT_Z","outputId":"30a77526-3b9a-4d5b-a89e-a5f769d4c808","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T14:55:34.077271Z","iopub.execute_input":"2025-09-17T14:55:34.077547Z","iopub.status.idle":"2025-09-17T14:55:35.344913Z","shell.execute_reply.started":"2025-09-17T14:55:34.077520Z","shell.execute_reply":"2025-09-17T14:55:35.344155Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = \"/kaggle/input/plantdisease/PlantVillage\"   #  dataset folder \nbase_dir = \"/kaggle/working/dataset_binary\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T20:18:19.517055Z","iopub.execute_input":"2025-09-17T20:18:19.517360Z","iopub.status.idle":"2025-09-17T20:18:19.521138Z","shell.execute_reply.started":"2025-09-17T20:18:19.517340Z","shell.execute_reply":"2025-09-17T20:18:19.520395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare binary dataset: Healthy vs Diseased\n\ndata_dir = \"/kaggle/input/plantdisease/PlantVillage\"\nbase_dir = \"/kaggle/working/dataset_binary\"\n\nimport shutil\nfrom sklearn.model_selection import train_test_split\nfor split in [\"train\",\"val\",\"test\"]:\n    for cls in [\"Healthy\",\"Diseased\"]:\n        os.makedirs(os.path.join(base_dir, split, cls), exist_ok=True)\n\n# Move/copy images into binary folders\nfor cls in sorted(os.listdir(data_dir)):\n    cls_path = os.path.join(data_dir, cls)\n    if not os.path.isdir(cls_path):\n        continue\n    label = \"Healthy\" if \"healthy\" in cls.lower() else \"Diseased\"\n    imgs = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n    if len(imgs) == 0:\n        continue\n    train, test = train_test_split(imgs, test_size=0.2, random_state=42)\n    val, test = train_test_split(test, test_size=0.5, random_state=42)\n    for subset, subset_dir in zip([train, val, test], [os.path.join(base_dir,'train',label), os.path.join(base_dir,'val',label), os.path.join(base_dir,'test',label)]):\n        for img in subset:\n            try:\n                shutil.copy(img, subset_dir)\n            except Exception as e:\n                print(\"Could not copy\", img, \"=>\", e)\n\n# Quick counts\nfor split in [\"train\",\"val\",\"test\"]:\n    print(\"\\nCounts in\", split)\n    for cls in [\"Healthy\",\"Diseased\"]:\n        p = os.path.join(base_dir, split, cls)\n        n = len([f for f in os.listdir(p) if f.lower().endswith(('.png','.jpg','.jpeg'))])\n        print(f\"  {cls}: {n}\")","metadata":{"id":"GcGvKHJPF6bA","outputId":"1d6825cb-e954-4222-d1fb-aecb78f36b1b","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T20:25:01.626329Z","iopub.execute_input":"2025-09-17T20:25:01.626680Z","iopub.status.idle":"2025-09-17T20:27:11.501758Z","shell.execute_reply.started":"2025-09-17T20:25:01.626659Z","shell.execute_reply":"2025-09-17T20:27:11.501111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#imageDataGenerator\nIMG_SIZE = (224,224)\nBATCH_SIZE = 32\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_gen = train_datagen.flow_from_directory(\n    os.path.join(base_dir,'train'), \n    target_size=IMG_SIZE, \n    batch_size=BATCH_SIZE, \n    class_mode='binary'\n)\nval_gen = val_test_datagen.flow_from_directory(\n    os.path.join(base_dir,'val'), \n    target_size=IMG_SIZE, \n    batch_size=BATCH_SIZE, \n    class_mode='binary'\n)\ntest_gen = val_test_datagen.flow_from_directory(\n    os.path.join(base_dir,'test'), \n    target_size=IMG_SIZE, \n    batch_size=BATCH_SIZE, \n    class_mode='binary', \n    shuffle=False\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T20:33:08.160585Z","iopub.execute_input":"2025-09-17T20:33:08.161563Z","iopub.status.idle":"2025-09-17T20:33:08.348326Z","shell.execute_reply.started":"2025-09-17T20:33:08.161518Z","shell.execute_reply":"2025-09-17T20:33:08.347798Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, shutil\nfrom sklearn.model_selection import train_test_split\n\n# Kaggle dataset path\ndata_dir = \"/kaggle/input/plantdisease/PlantVillage\"   #  new dataset folder \nbase_dir = \"/kaggle/working/dataset_binary\"            # dataset save \n\n# Create binary directories\nfor split in [\"train\",\"val\",\"test\"]:\n    for cls in [\"Healthy\",\"Diseased\"]:\n        os.makedirs(os.path.join(base_dir, split, cls), exist_ok=True)\n\n# Move/copy images into binary folders\nfor cls in sorted(os.listdir(data_dir)):\n    cls_path = os.path.join(data_dir, cls)\n    if not os.path.isdir(cls_path):\n        continue\n    label = \"Healthy\" if \"healthy\" in cls.lower() else \"Diseased\"\n    imgs = [os.path.join(cls_path, f) for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n    if len(imgs) == 0:\n        continue\n    train, test = train_test_split(imgs, test_size=0.2, random_state=42)\n    val, test = train_test_split(test, test_size=0.5, random_state=42)\n    for subset, subset_dir in zip(\n        [train, val, test],\n        [os.path.join(base_dir,'train',label),\n         os.path.join(base_dir,'val',label),\n         os.path.join(base_dir,'test',label)]\n    ):\n        for img in subset:\n            try:\n                shutil.copy(img, subset_dir)\n            except Exception as e:\n                print(\"Could not copy\", img, \"=>\", e)\n\n# Quick counts\nfor split in [\"train\",\"val\",\"test\"]:\n    print(\"\\nCounts in\", split)\n    for cls in [\"Healthy\",\"Diseased\"]:\n        p = os.path.join(base_dir, split, cls)\n        n = len([f for f in os.listdir(p) if f.lower().endswith(('.png','.jpg','.jpeg'))])\n        print(f\"  {cls}: {n}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T15:49:05.739414Z","iopub.execute_input":"2025-09-17T15:49:05.739697Z","iopub.status.idle":"2025-09-17T15:52:42.886093Z","shell.execute_reply.started":"2025-09-17T15:49:05.739676Z","shell.execute_reply":"2025-09-17T15:52:42.885264Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport os\n\n\n# Dataset base directory (already created in the previous step)\nbase_dir = \"/kaggle/working/dataset_binary\"\n\n# ImageDataGenerators (augmentation for train)   image size\nIMG_SIZE = (224,224)\nBATCH_SIZE = 32\n\n# Train data generator with augmentation\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=20,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n# Validation/Test generator (only rescale)\nval_test_datagen = ImageDataGenerator(rescale=1./255)\n\n# Create generators\ntrain_gen = train_datagen.flow_from_directory(\n    os.path.join(base_dir,'train'), \n    target_size=IMG_SIZE, \n    batch_size=BATCH_SIZE, \n    class_mode='binary'\n)\nval_gen = val_test_datagen.flow_from_directory(\n    os.path.join(base_dir,'val'),\n    target_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_mode='binary'\n)\ntest_gen = val_test_datagen.flow_from_directory(\n    os.path.join(base_dir,'test'),\n    target_size=IMG_SIZE, \n    batch_size=BATCH_SIZE, \n    class_mode='binary', \n    shuffle=False\n)","metadata":{"id":"vl3ZwABwGJvh","outputId":"281fdc0f-a839-4243-c34b-44bd58fa9439","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T16:09:07.785988Z","iopub.execute_input":"2025-09-17T16:09:07.786298Z","iopub.status.idle":"2025-09-17T16:09:07.996039Z","shell.execute_reply.started":"2025-09-17T16:09:07.786279Z","shell.execute_reply":"2025-09-17T16:09:07.995245Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n\n# ---------------- CNN MODEL ----------------\ncnn_model = Sequential([\n    Conv2D(32, (3,3), activation='relu', input_shape=(224,224,3)),\n    MaxPooling2D(2,2),\n    Conv2D(64, (3,3), activation='relu'),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dense(128, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')  # binary classification\n])\n\ncnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train CNN\nhistory_cnn = cnn_model.fit(train_gen, validation_data=val_gen, epochs=10)\n\n\n# ---------------- Evaluate CNN ----------------\ny_true = test_gen.classes\ny_prob_cnn = cnn_model.predict(test_gen)\ny_pred_cnn = (y_prob_cnn > 0.5).astype('int32')\n\nprint(\"✅ CNN Classification Report:\\n\", classification_report(y_true, y_pred_cnn))\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T21:14:29.177452Z","iopub.execute_input":"2025-09-17T21:14:29.177999Z","iopub.status.idle":"2025-09-17T21:41:15.641019Z","shell.execute_reply.started":"2025-09-17T21:14:29.177973Z","shell.execute_reply":"2025-09-17T21:41:15.640410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- MobileNetV2 MODEL ----------------\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n\nbase_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\nbase_model.trainable = False  # freeze base layers\n\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dropout(0.5)(x)\noutput = Dense(1, activation='sigmoid')(x)\n\nmobilenet_model = Model(inputs=base_model.input, outputs=output)\nmobilenet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Train MobileNetV2\nhistory_mobilenet = mobilenet_model.fit(train_gen, validation_data=val_gen, epochs=10)\n\n\n# ---------------- Evaluate MobileNetV2 ----------------\ny_prob_mnet = mobilenet_model.predict(test_gen)\ny_pred_mnet = (y_prob_mnet > 0.5).astype('int32')\n\nprint(\"✅ MobileNetV2 Classification Report:\\n\", classification_report(y_true, y_pred_mnet))\n\n\n# ---------------- Confusion Matrix (MobileNetV2) ----------------\ncm = confusion_matrix(y_true, y_pred_mnet)\nplt.figure(figsize=(5,4))\nsns.heatmap(cm, annot=True, fmt='d', xticklabels=[\"Healthy\",\"Diseased\"], yticklabels=[\"Healthy\",\"Diseased\"], cmap=\"Blues\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.title(\"Confusion Matrix (MobileNetV2)\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T21:42:00.013411Z","iopub.execute_input":"2025-09-17T21:42:00.014084Z","iopub.status.idle":"2025-09-17T22:09:06.056742Z","shell.execute_reply.started":"2025-09-17T21:42:00.014060Z","shell.execute_reply":"2025-09-17T22:09:06.056013Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- Summary Table ----------------\nresults = {\n    \"Model\": [\"CNN\",\"MobileNetV2\"],\n    \"Accuracy\": [accuracy_score(y_true, y_pred_cnn), accuracy_score(y_true, y_pred_mnet)],\n    \"Precision\": [precision_score(y_true, y_pred_cnn), precision_score(y_true, y_pred_mnet)],\n    \"Recall\": [recall_score(y_true, y_pred_cnn), recall_score(y_true, y_pred_mnet)],\n    \"F1\": [f1_score(y_true, y_pred_cnn), f1_score(y_true, y_pred_mnet)]\n}\ndf_results = pd.DataFrame(results)\nprint(\"\\n✅ Summary Table:\\n\", df_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T22:10:47.348385Z","iopub.execute_input":"2025-09-17T22:10:47.348653Z","iopub.status.idle":"2025-09-17T22:10:47.368948Z","shell.execute_reply.started":"2025-09-17T22:10:47.348633Z","shell.execute_reply":"2025-09-17T22:10:47.368272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Grad-CAM example for MobileNetV2 (choose a conv layer name if needed)\nimport tensorflow as tf\nimport cv2, numpy as np\ndef get_gradcam_heatmap(model, img_array, last_conv_layer_name):\n    grad_model = tf.keras.models.Model([model.inputs], [model.get_layer(last_conv_layer_name).output, model.output])\n    with tf.GradientTape() as tape:\n        conv_outputs, predictions = grad_model(img_array)\n        loss = predictions[:, 0]\n    grads = tape.gradient(loss, conv_outputs)\n    pooled_grads = tf.reduce_mean(grads, axis=(0,1,2))\n    conv_outputs = conv_outputs[0]\n    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n    heatmap = np.maximum(heatmap, 0) / (np.max(heatmap) + 1e-8)\n    return heatmap\n\n# Use a test image\nif len(test_gen.filepaths) > 0:\n    img_path = test_gen.filepaths[0]\n    img = tf.keras.utils.load_img(img_path, target_size=IMG_SIZE)\n    img_array = tf.keras.utils.img_to_array(img) / 255.0\n    img_array = np.expand_dims(img_array, axis=0)\n    # Last conv layer name in MobileNetV2 often 'Conv_1' but may vary\n    layer_name = None\n    for layer in mobilenet_model.layers[::-1]:\n        if isinstance(layer, tf.keras.layers.Conv2D):\n            layer_name = layer.name\n            break\n    print(\"Using last conv layer:\", layer_name)\n    heatmap = get_gradcam_heatmap(mobilenet_model, img_array, layer_name)\n    plt.matshow(heatmap)\n    plt.title(\"Grad-CAM heatmap\")\n    plt.show()\nelse:\n    print(\"No test images found.\")","metadata":{"id":"wrp8G6M_JmI-","outputId":"36c00154-5485-463c-f604-7236dc732c23","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T22:14:16.994931Z","iopub.execute_input":"2025-09-17T22:14:16.995474Z","iopub.status.idle":"2025-09-17T22:14:17.878282Z","shell.execute_reply.started":"2025-09-17T22:14:16.995453Z","shell.execute_reply":"2025-09-17T22:14:17.877597Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save trained models to Drive (optional)\nos.makedirs('/content/drive/MyDrive/plant_models', exist_ok=True)\ncnn_model.save('/content/drive/MyDrive/plant_models/cnn_model.keras')\nmobilenet_model.save('/content/drive/MyDrive/plant_models/mobilenet_model.keras')\nprint(\"Models saved to /content/drive/MyDrive/plant_models/\")","metadata":{"id":"18QDWAfFJuXI","outputId":"c3eaed8d-ea6d-4e94-e2cc-fadd04900650","trusted":true,"execution":{"iopub.status.busy":"2025-09-17T22:15:29.874834Z","iopub.execute_input":"2025-09-17T22:15:29.875093Z","iopub.status.idle":"2025-09-17T22:15:31.494151Z","shell.execute_reply.started":"2025-09-17T22:15:29.875072Z","shell.execute_reply":"2025-09-17T22:15:31.493205Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ✅ Save trained models in Kaggle\nimport os\n\nsave_dir = \"/kaggle/working/plant_models\"\nos.makedirs(save_dir, exist_ok=True)\n\ncnn_model.save(os.path.join(save_dir, \"cnn_model.keras\"))\nmobilenet_model.save(os.path.join(save_dir, \"mobilenet_model.keras\"))\n\nprint(f\"✅ Models saved in {save_dir}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T22:15:54.822678Z","iopub.execute_input":"2025-09-17T22:15:54.823294Z","iopub.status.idle":"2025-09-17T22:15:56.410625Z","shell.execute_reply.started":"2025-09-17T22:15:54.823265Z","shell.execute_reply":"2025-09-17T22:15:56.409976Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Dataset folder path\ndata_dir = \"/kaggle/input/plantdisease\"\n\n# Check files inside\nprint(os.listdir(data_dir))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T20:02:19.401169Z","iopub.execute_input":"2025-09-17T20:02:19.401449Z","iopub.status.idle":"2025-09-17T20:02:19.416222Z","shell.execute_reply.started":"2025-09-17T20:02:19.401423Z","shell.execute_reply":"2025-09-17T20:02:19.415477Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- Training Curves (CNN) ----------------\nplt.figure(figsize=(12,5))\n\n# Accuracy\nplt.subplot(1,2,1)\nplt.plot(history_cnn.history['accuracy'], label='Train Accuracy')\nplt.plot(history_cnn.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"CNN Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\n# Loss\nplt.subplot(1,2,2)\nplt.plot(history_cnn.history['loss'], label='Train Loss')\nplt.plot(history_cnn.history['val_loss'], label='Val Loss')\nplt.title(\"CNN Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T22:24:43.226927Z","iopub.execute_input":"2025-09-17T22:24:43.227619Z","iopub.status.idle":"2025-09-17T22:24:43.507122Z","shell.execute_reply.started":"2025-09-17T22:24:43.227595Z","shell.execute_reply":"2025-09-17T22:24:43.506469Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ---------------- Training Curves (MobileNetV2) ----------------\nplt.figure(figsize=(12,5))\n\n# Accuracy\nplt.subplot(1,2,1)\nplt.plot(history_mobilenet.history['accuracy'], label='Train Accuracy')\nplt.plot(history_mobilenet.history['val_accuracy'], label='Val Accuracy')\nplt.title(\"MobileNetV2 Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\n\n# Loss\nplt.subplot(1,2,2)\nplt.plot(history_mobilenet.history['loss'], label='Train Loss')\nplt.plot(history_mobilenet.history['val_loss'], label='Val Loss')\nplt.title(\"MobileNetV2 Loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.legend()\n\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T22:24:55.561288Z","iopub.execute_input":"2025-09-17T22:24:55.561923Z","iopub.status.idle":"2025-09-17T22:24:55.855713Z","shell.execute_reply.started":"2025-09-17T22:24:55.561902Z","shell.execute_reply":"2025-09-17T22:24:55.855014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}